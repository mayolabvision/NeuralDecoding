# Decoding of eye movement trajectories by neuronal populations in cortex
In this project, we are using machine learning methods to investigate the relationship between cortical activity and eye movements in macaque monkeys. We recorded from a small population of neurons in two regions of the brain known to play a role in eye movement generation, the Frontal Eye Fields (FEF) and the Medial Temporal (MT) area, while a monkey kept their eyes fixated on a moving target. The main goal of this work is to reconstruct where the monkey's eyes were looking on a moment-to-moment basis based on how the spiking activity of FEF and MT neurons. 

This repository contains python jupyter notebooks (with various decoding and machine learning methods) and datasets (with eye positions/velocities and neuronal spiking activity). The packages used in the python notebooks are from the Kording Lab's Neural Decoding package ([GitHub Link](https://github.com/KordingLab/Neural_Decoding)) and the data was collected by Dr. Patrick Mayo during his postdoc at Duke University. 

## Project Information:
### Motivation: 
In our lab we are interested in understanding how the brain coordinates eye movements. We move our eyes constantly, around ~3 times per second, to redirect our attention towards things in our environment that interest us. This is something we do effortlessly, but the brain circuitry in control of visual processing and eye movements is actually extremely complex. 
As an example, imagine you are trying to swat a fly. As the fly zooms around the room, you are trying to keep your eyes fixated on its flight trajectory so when it eventually lands you can be ready to pounce. In your brain, there are different regions responsible for handling different aspects of this scenario. There are *sensory* regions that keep track of where the fly is and how fast it is moving; and then there are *motor* regions which determine where you'll need to look based on the information sent to it by the sensory areas. To accurately keep your eyes positioned on the fly, these brain regions with seemingly different roles have to rapidly communicate back and forth.
This relaying of sensorimotor signals occurs at the level of neurons, which act as information messengers via electrical impulses. Neurons within one brain region and across different brain regions communicate with one another to accomplish some goal, like moving the eyes to track a fly. But even within a single brain region, neurons care about different things and are sensitive to different aspects of our environments. Some neurons may care about the identity of a visual stimulus (e.g. fly, bee, or butterfly) whereas other neurons are sensitive to what direction the flying insect is moving. 

It is still somewhat unknown how these neurons, that are selective to different features of the visual world, come together to accomplish some goal. How can we determine what neurons *care about* and how do their selectivities to certain stimuli modualte their activity?  

### Basic definitions:
* **Neuron**: a specialized cell transmitting nerve impulses
* **Machine Learning**: enables researchers to discover statistical patterns in large datasets to solve a wide variety of tasks, including in neuroscience
* **Decoding**: the act, process, or result of extracting meaning or usable information 
* **Fixation**: the maintaining of the gaze on a single location
* **Spiking activity**: in behavioral neuroscience, a train of electrical signals recorded from an individual neuron in the brain. Spikes are the action potentials or signals generated by neurons to communicate with one another
* **Sensorimotor network**: responsible for sensing physical inputs, converting them to electrical signals that travel throughout the brain network, and then initiating a physical response
* **Saccade**: a rapid movement of the eye between fixation points
* **Smooth pursuit**: a type of eye movement in which the eyes remain fixated on a moving object

### Experimental Paradigm:



## Getting Started:


